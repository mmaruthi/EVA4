{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled13.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyONdp7AYxJJsOSyti/a26Qe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmaruthi/EVA4/blob/master/Model1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCcsvXaED2wy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "75601774-9379-4d14-bf8b-d64068678c40"
      },
      "source": [
        "# Mounting the drive \n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWVwgX3kEXDq",
        "colab_type": "text"
      },
      "source": [
        "# Get the CIFAR10 data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWdN3z0EEFCT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "170217b3-36d9-40f3-9d70-25dbee018f46"
      },
      "source": [
        "from torchvision import datasets \n",
        "\n",
        "inpdata = datasets.CIFAR10('./data',train=True,download=True)\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2cB5TTXMgF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# add path to our library in default search path\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/EVA4')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A87UkwJE6lH",
        "colab_type": "text"
      },
      "source": [
        "# See the data\n",
        "Let us see some training images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knD3R74pFHTL",
        "colab_type": "text"
      },
      "source": [
        "# Transformations "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrOIHF_OFKge",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "1820f33e-df9c-4b64-daef-49280a0f2611"
      },
      "source": [
        "import numpy as np\n",
        "import S7-datatransforms\n",
        "from torchvision import transforms\n",
        "\n",
        "mean = (0.49139968, 0.48215841, 0.44653091)\n",
        "stdev = (0.24703223, 0.24348513, 0.26158784)\n",
        "\n",
        "trans = Transforms_customs.Transforms(normalize=True, mean=channel_means, stdev=channel_stdevs)\n",
        "\n",
        "# Train Phase transformations\n",
        "train_transforms = trans.train_transforms([\n",
        "                                       transforms.RandomRotation((-15.0, 15.0), fill=tuple(fillmeans)),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       ], \n",
        "                                       \n",
        "                                       )\n",
        "\n",
        "            \n",
        "# Test Phase transformations\n",
        "test_transforms = trans.test_transforms()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-27-a6745e5c1810>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    import S7-datatransforms\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RvOFUyoIiEv",
        "colab_type": "text"
      },
      "source": [
        "# Create Train and Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl5PBbkwImu-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "505151d5-e619-44f9-b163-cd09295ac6c9"
      },
      "source": [
        "train = datasets.CIFAR10('./data', train=False, download=True, transform=train_transforms)\n",
        "test = datasets.CIFAR10('./data', train=False, download=True, transform=test_transforms)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-31b984fe8627>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCIFAR10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_transforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCIFAR10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_transforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_transforms' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-XJHiJtIuSt",
        "colab_type": "text"
      },
      "source": [
        "# Data Loader arguments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gc1hP78tIzOi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "e43d1686-0a78-49c2-bde7-0d7421d0059c"
      },
      "source": [
        "import S7-data-loader\n",
        "\n",
        "dataloader = S7-data-loader.DataLoader()\n",
        "\n",
        "# train dataloader\n",
        "train_loader = dataloader.load(train)\n",
        "\n",
        "# test dataloader\n",
        "test_loader = dataloader.load(test)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-29-f8f9a977db9f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    import S7-data-loader\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ebvRaQqJNXv",
        "colab_type": "text"
      },
      "source": [
        "# Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fe8jr0YJQOn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import S7-Model \n",
        "import torch \n",
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "model = S7-Model.Net()\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "model.to(device)\n",
        "summary(model, input_size=(3, 32, 32))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cu4wRX-WLGAi",
        "colab_type": "text"
      },
      "source": [
        "# Train and Test the model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNX9W00SLKYr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "EPOCHS = 20\n",
        "L2lambda = 0\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, nesterov=True, weight_decay=L2lambda)\n",
        "#scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.5, steps_per_epoch=len(train_loader), epochs=EPOCHS)\n",
        "L1lambda = 0\n",
        "model.gotrain(optimizer, train_loader, test_loader, EPOCHS, \"/content/drive/My Drive\", scheduler, True, L1lambda)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}